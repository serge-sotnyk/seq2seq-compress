{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Convolution1D, Dot, Dense, Activation, Concatenate\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_token_index': {' ': 0, '!': 1, '#': 2, '$': 3, '%': 4, '&': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, '+': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '<': 27, '=': 28, '>': 29, '?': 30, '@': 31, 'A': 32, 'B': 33, 'C': 34, 'D': 35, 'E': 36, 'F': 37, 'G': 38, 'H': 39, 'I': 40, 'J': 41, 'K': 42, 'L': 43, 'M': 44, 'N': 45, 'O': 46, 'P': 47, 'Q': 48, 'R': 49, 'S': 50, 'T': 51, 'U': 52, 'V': 53, 'W': 54, 'X': 55, 'Y': 56, 'Z': 57, '\\\\': 58, '^': 59, '_': 60, '`': 61, 'a': 62, 'b': 63, 'c': 64, 'd': 65, 'e': 66, 'f': 67, 'g': 68, 'h': 69, 'i': 70, 'j': 71, 'k': 72, 'l': 73, 'm': 74, 'n': 75, 'o': 76, 'p': 77, 'q': 78, 'r': 79, 's': 80, 't': 81, 'u': 82, 'v': 83, 'w': 84, 'x': 85, 'y': 86, 'z': 87, '~': 88, '¡': 89, '¢': 90, '£': 91, '¤': 92, '¥': 93, '¦': 94, '§': 95, '¨': 96, '©': 97, '¬': 98, '®': 99, '¯': 100, '°': 101, '±': 102, '³': 103, '´': 104, 'µ': 105, '¸': 106, '¹': 107, 'º': 108, '¼': 109, '½': 110, '¾': 111, '¿': 112, 'Á': 113, 'Â': 114, 'Ã': 115, 'Ä': 116, 'Å': 117, 'Ç': 118, 'È': 119, 'É': 120, 'Í': 121, 'Ñ': 122, 'Ó': 123, 'Ö': 124, '×': 125, 'Ü': 126, 'à': 127, 'á': 128, 'â': 129, 'ã': 130, 'ä': 131, 'å': 132, 'æ': 133, 'ç': 134, 'è': 135, 'é': 136, 'ê': 137, 'ë': 138, 'ì': 139, 'í': 140, 'ï': 141, 'ð': 142, 'ñ': 143, 'ò': 144, 'ó': 145, 'ô': 146, 'ö': 147, 'ø': 148, 'ù': 149, 'ú': 150, 'û': 151, 'ü': 152, 'ý': 153, 'ā': 154, 'ă': 155, 'Ć': 156, 'ć': 157, 'Ċ': 158, 'ċ': 159, 'č': 160, 'Đ': 161, 'đ': 162, 'ė': 163, 'ę': 164, 'ğ': 165, 'Ġ': 166, 'ġ': 167, 'Ħ': 168, 'ħ': 169, 'ī': 170, 'İ': 171, 'ı': 172, 'Ł': 173, 'ł': 174, 'Ń': 175, 'ń': 176, 'ō': 177, 'ő': 178, 'œ': 179, 'Ş': 180, 'ş': 181, 'Š': 182, 'š': 183, 'ū': 184, 'ź': 185, 'Ż': 186, 'ż': 187, 'Ž': 188, 'ž': 189, 'Ɩ': 190, 'ə': 191, 'ʻ': 192, '˜': 193, '΄': 194, 'Α': 195, 'Τ': 196, 'α': 197, 'β': 198, 'ο': 199, 'υ': 200, 'Ђ': 201, 'А': 202, 'а': 203, 'в': 204, 'е': 205, 'й': 206, 'о': 207, 'р': 208, 'с': 209, 'ѕ': 210, 'і': 211, '\\u200b': 212, '\\u200e': 213, '‐': 214, '‑': 215, '‒': 216, '―': 217, '‚': 218, '”': 219, '†': 220, '′': 221, '″': 222, '※': 223, '⁄': 224, '⁈': 225, '€': 226, '№': 227, '℠': 228, '™': 229, '−': 230, '√': 231, '⌖': 232, '⎙': 233, '─': 234, '▾': 235, '◦': 236, '唯': 237, '抯': 238, '檚': 239, '痴': 240, '簧': 241, '裕': 242, '鈥': 243, '\\uf611': 244, '\\ufeff': 245, '．': 246, '￥': 247, '�': 248}, 'target_token_index': {'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, '+': 12, ',': 13, '-': 14, '.': 15, '/': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ':': 27, ';': 28, '=': 29, '>': 30, '?': 31, '@': 32, 'A': 33, 'B': 34, 'C': 35, 'D': 36, 'E': 37, 'F': 38, 'G': 39, 'H': 40, 'I': 41, 'J': 42, 'K': 43, 'L': 44, 'M': 45, 'N': 46, 'O': 47, 'P': 48, 'Q': 49, 'R': 50, 'S': 51, 'T': 52, 'U': 53, 'V': 54, 'W': 55, 'X': 56, 'Y': 57, 'Z': 58, '\\\\': 59, '_': 60, '`': 61, 'a': 62, 'b': 63, 'c': 64, 'd': 65, 'e': 66, 'f': 67, 'g': 68, 'h': 69, 'i': 70, 'j': 71, 'k': 72, 'l': 73, 'm': 74, 'n': 75, 'o': 76, 'p': 77, 'q': 78, 'r': 79, 's': 80, 't': 81, 'u': 82, 'v': 83, 'w': 84, 'x': 85, 'y': 86, 'z': 87, '~': 88, '¢': 89, '£': 90, '¤': 91, '¥': 92, '§': 93, '©': 94, '®': 95, '°': 96, '´': 97, 'µ': 98, '¹': 99, '½': 100, '¿': 101, 'Á': 102, 'Â': 103, 'Ã': 104, 'Ä': 105, 'Å': 106, 'É': 107, 'Í': 108, 'Ñ': 109, 'Ó': 110, 'Ö': 111, '×': 112, 'Ü': 113, 'á': 114, 'â': 115, 'ã': 116, 'ä': 117, 'å': 118, 'æ': 119, 'ç': 120, 'è': 121, 'é': 122, 'ê': 123, 'ë': 124, 'ì': 125, 'í': 126, 'ï': 127, 'ñ': 128, 'ó': 129, 'ô': 130, 'ö': 131, 'ø': 132, 'ù': 133, 'ú': 134, 'û': 135, 'ü': 136, 'ā': 137, 'ă': 138, 'ć': 139, 'Ċ': 140, 'č': 141, 'ę': 142, 'ğ': 143, 'ġ': 144, 'İ': 145, 'ı': 146, 'ł': 147, 'ń': 148, 'ō': 149, 'œ': 150, 'Ş': 151, 'ş': 152, 'Š': 153, 'š': 154, 'ž': 155, 'ə': 156, '˜': 157, 'Τ': 158, 'α': 159, 'ο': 160, 'А': 161, 'а': 162, '\\u200b': 163, '\\u200e': 164, '―': 165, '‚': 166, '†': 167, '′': 168, '※': 169, '€': 170, '№': 171, '℠': 172, '™': 173, '◦': 174, '抯': 175, '裕': 176, '\\uf611': 177, '\\ufeff': 178, '�': 179}, 'num_encoder_tokens': 249, 'max_decoder_seq_length': 245, 'max_encoder_seq_length': 511, 'num_decoder_tokens': 180}\n"
     ]
    }
   ],
   "source": [
    "with open('options.json', encoding='utf-8') as f:\n",
    "    options = json.load(f)\n",
    "print(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None, options['num_encoder_tokens']))\n",
    "    # Encoder\n",
    "    x_encoder = Convolution1D(256, kernel_size=3, activation='relu',\n",
    "                              padding='causal')(encoder_inputs)\n",
    "    x_encoder = Convolution1D(256, kernel_size=3, activation='relu',\n",
    "                              padding='causal', dilation_rate=2)(x_encoder)\n",
    "    x_encoder = Convolution1D(256, kernel_size=3, activation='relu',\n",
    "                              padding='causal', dilation_rate=4)(x_encoder)\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, options['num_decoder_tokens']))\n",
    "    # Decoder\n",
    "    x_decoder = Convolution1D(256, kernel_size=3, activation='relu',\n",
    "                              padding='causal')(decoder_inputs)\n",
    "    x_decoder = Convolution1D(256, kernel_size=3, activation='relu',\n",
    "                              padding='causal', dilation_rate=2)(x_decoder)\n",
    "    x_decoder = Convolution1D(256, kernel_size=3, activation='relu',\n",
    "                              padding='causal', dilation_rate=4)(x_decoder)\n",
    "    # Attention\n",
    "    attention = Dot(axes=[2, 2])([x_decoder, x_encoder])\n",
    "    attention = Activation('softmax')(attention)\n",
    "    \n",
    "    context = Dot(axes=[2, 1])([attention, x_encoder])\n",
    "    decoder_combined_context = Concatenate(axis=-1)([context, x_decoder])\n",
    "    \n",
    "    decoder_outputs = Convolution1D(64, kernel_size=3, activation='relu',\n",
    "                                    padding='causal')(decoder_combined_context)\n",
    "    decoder_outputs = Convolution1D(64, kernel_size=3, activation='relu',\n",
    "                                    padding='causal')(decoder_outputs)\n",
    "    # Output\n",
    "    decoder_dense = Dense(options['num_decoder_tokens'], activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = create_model()\n",
    "#model.load_weights('s2s.h5')\n",
    "model = load_model('s2s.h5')\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs = [\n",
    "    \"There are numerous weaknesses with the bag of words model especially when applied to natural language processing tasks that graph ranking algorithms such as TextRank are able to address.\",\n",
    "    \"Since purple yams happen to be starchy root vegetables, they also happen to be a great source of carbs, potassium, and vitamin C.\",\n",
    "    \"Recurrent Neural Networks (RNNs) have been used successfully for many tasks involving sequential data such as machine translation, sentiment analysis, image captioning, time-series prediction etc.\",\n",
    "    \"Improved RNN models such as Long Short-Term Memory networks (LSTMs) enable training on long sequences overcoming problems like vanishing gradients.\",\n",
    "    \"However, even the more advanced models have their limitations and researchers had a hard time developing high-quality models when working with long data sequences.\",\n",
    "    \"In machine translation, for example, the RNN has to find connections between long input and output sentences composed of dozens of words.\",\n",
    "    \"It seemed that the existing RNN architectures needed to be changed and adapted to better deal with such tasks.\",\n",
    "    \"Wenger ended his 22-year Gunners reign after the 2017-18 season and previously stated he intended to take charge of a new club in early 2019.\",\n",
    "    \"It will not prevent the Frenchman from resuming his career in football.\",\n",
    "    \"However 12 months out of work has given him a different outlook and may influence his next move.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input_to_inputs(ui: List[str]):\n",
    "    max_encoder_seq_length = options['max_encoder_seq_length']\n",
    "    num_encoder_tokens = options['num_encoder_tokens']\n",
    "    input_token_index = options['input_token_index']\n",
    "    encoder_input_data = np.zeros(\n",
    "        (len(ui), max_encoder_seq_length, num_encoder_tokens),\n",
    "        dtype='float32')\n",
    "\n",
    "    for i, input_text in enumerate(ui):\n",
    "        for t, char in enumerate(input_text):\n",
    "            encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "       \n",
    "    return encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = user_input_to_inputs(user_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(inputs:np.array, user_inputs: List[str]):\n",
    "    max_decoder_seq_length = options['max_decoder_seq_length']\n",
    "    num_decoder_tokens = options['num_decoder_tokens']\n",
    "    input_token_index = options['input_token_index']\n",
    "    target_token_index = options['target_token_index']\n",
    "    \n",
    "    # Define sampling models\n",
    "    reverse_input_char_index = dict(\n",
    "        (i, char) for char, i in input_token_index.items())\n",
    "    reverse_target_char_index = dict(\n",
    "        (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "    in_encoder = inputs\n",
    "    in_decoder = np.zeros(\n",
    "        (len(in_encoder), max_decoder_seq_length, num_decoder_tokens),\n",
    "        dtype='float32')\n",
    "\n",
    "    in_decoder[:, 0, target_token_index[\"\\t\"]] = 1\n",
    "\n",
    "    predict = np.zeros(\n",
    "        (len(in_encoder), max_decoder_seq_length),\n",
    "        dtype='float32')\n",
    "\n",
    "    for i in range(max_decoder_seq_length - 1):\n",
    "        predict = model.predict([in_encoder, in_decoder])\n",
    "        predict = predict.argmax(axis=-1)\n",
    "        predict_ = predict[:, i].ravel().tolist()\n",
    "        for j, x in enumerate(predict_):\n",
    "            in_decoder[j, i + 1, x] = 1\n",
    "\n",
    "    for seq_index in range(len(in_encoder)):\n",
    "        # Take one sequence (part of the training set)\n",
    "        # for trying out decoding.\n",
    "        output_seq = predict[seq_index, :].ravel().tolist()\n",
    "        decoded = []\n",
    "        for x in output_seq:\n",
    "            if reverse_target_char_index[x] == \"\\n\":\n",
    "                break\n",
    "            else:\n",
    "                decoded.append(reverse_target_char_index[x])\n",
    "        decoded_sentence = \"\".join(decoded)\n",
    "        print('-')\n",
    "        print('Input sentence:', user_inputs[seq_index])\n",
    "        print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: There are numerous weaknesses with the bag of words model especially when applied to natural language processing tasks that graph ranking algorithms such as TextRank are able to address.\n",
      "Decoded sentence: Graph ranking are able to address.\n",
      "-\n",
      "Input sentence: Since purple yams happen to be starchy root vegetables, they also happen to be a great source of carbs, potassium, and vitamin C.\n",
      "Decoded sentence: Since purple happen to be a great source of carbs.\n",
      "-\n",
      "Input sentence: Recurrent Neural Networks (RNNs) have been used successfully for many tasks involving sequential data such as machine translation, sentiment analysis, image captioning, time-series prediction etc.\n",
      "Decoded sentence: Recurrent Neural Networks.\n",
      "-\n",
      "Input sentence: Improved RNN models such as Long Short-Term Memory networks (LSTMs) enable training on long sequences overcoming problems like vanishing gradients.\n",
      "Decoded sentence: Improved RNN models sequences.\n",
      "-\n",
      "Input sentence: However, even the more advanced models have their limitations and researchers had a hard time developing high-quality models when working with long data sequences.\n",
      "Decoded sentence: When working with long data sequences.\n",
      "-\n",
      "Input sentence: In machine translation, for example, the RNN has to find connections between long input and output sentences composed of dozens of words.\n",
      "Decoded sentence: The RNN has to find connections between long input and output sentences composed of dozens of words.\n",
      "-\n",
      "Input sentence: It seemed that the existing RNN architectures needed to be changed and adapted to better deal with such tasks.\n",
      "Decoded sentence: The existing RNN architectures needed to better deal with tasks.\n",
      "-\n",
      "Input sentence: Wenger ended his 22-year Gunners reign after the 2017-18 season and previously stated he intended to take charge of a new club in early 2019.\n",
      "Decoded sentence: Wenger ended his 22-year Gunners reign after the 2016 18 season and previously stated he intended to take charge of a new club in early 2019.\n",
      "-\n",
      "Input sentence: It will not prevent the Frenchman from resuming his career in football.\n",
      "Decoded sentence: It will not prevent the Frenchman from resuming his career in football.\n",
      "-\n",
      "Input sentence: However 12 months out of work has given him a different outlook and may influence his next move.\n",
      "Decoded sentence: However 12 months out of work has given him a different outlook.\n"
     ]
    }
   ],
   "source": [
    "print_predictions(inputs, user_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
